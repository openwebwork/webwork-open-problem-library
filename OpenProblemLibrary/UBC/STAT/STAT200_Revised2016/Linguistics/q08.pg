#########################################################
# DESCRIPTION
## DBsubject('Statistics')
## DBchapter('Confidence intervals')
## DBsection('One sample proportion')
## Level(3)
## Date('2016/08/24')
## Author('Nelson Chen')
## Institution('University of British Columbia')
##KEYWORDS('Sample proportion', 'normal approximation')

#########################################################
DOCUMENT();
## Initializations: (Required)
loadMacros(
  "PGstandard.pl",
  "PGchoicemacros.pl",
  "parserRadioButtons.pl",
  "MathObjects.pl",
  "parserMultiAnswer.pl",
  "RserveClient.pl",
  "answerHints.pl",
  "unionTables.pl",
  "RserveClient.pl",
  "PGcourse.pl",
  "answerCustom.pl"
);

#########################################################
## Setup: this is where we use Perl and PG objects (Required)

Context("Numeric");
# warn("Student name: $studentName, login: $studentLogin, id: $studentID");
my $hash = crypt($studentLogin, 'a1');
# warn("crypt: $hash");
@nums = (0..9,'a'..'z','A'..'Z');
my %nums = map { $nums[$_] => $_ } 0..$#nums;
my $seed = 0;
$seed = $seed * 62 + $nums{$_} foreach split(//, substr($hash, -5, 5));
# warn("seed: " . $seed);

rserve_eval("set.seed($seed)");


@m= rserve_eval('
m <- round(runif(1, min=200, max=210))
');


@n= rserve_eval('
n <- round(runif(1, min=500, max=520))
');

@phat= rserve_eval('
phat <- (m/n)
round(phat, 3)
');


######Q1
$q1mc = new_multiple_choice();
$q1mc -> qa(
"What is a parameter of interest in this study?",
"The proportion of vowel letters in the language in which the text is
written."
);
$q1mc -> extra(
"The sample proportion of vowels, @phat[0].", 

"The proportion of vowel letters in the text.", 

"Whether a letter is a vowel in the language in which the text is written.", 

" The proportion of vowels in the sample from the text."

);

######Q2
$q2mc = new_multiple_choice();
$q2mc -> qa(
"In testing a hypothesis here, what would the null hypothesis be?",
"The proportion of vowel letters in the language in which the text is
written equals 0.381."
);
$q2mc -> extra(
"The proportion of the @n[0] letters chosen that are vowels equals 
@phat[0].",

"The proportion of vowel letters in the language in which the text is
written is greater than 0.381.",

"The proportion of vowel letters in the language in which the text is
written is equal to @phat[0].",

" The proportion of the @n[0] letters chosen that are vowels does
not equal 0.381.",

);


######Q3
$q3mc = new_multiple_choice();
$q3mc -> qa(
"What would the alternative hypothesis be?",
"The proportion of vowel letters in the language in which the text is
written does not equal 0.381."
);
$q3mc -> extra(
"The proportion of the @n[0] letters chosen that are vowels does
not equal @phat[0].",
"The proportion of vowel letters in the language in which the text is
written is greater than 0.381.",
"The proportion of vowel letters in the language in which the text is
written is greater than @phat[0].",
"The proportion of the @n[0] letters chosen that are vowels is
less than 0.381."
);


######Q4
$q4mc = new_multiple_choice();
$q4mc -> qa(
"Under the null hypothesis, what is the approximate sampling
distribution of the sample proportion?",
"\(N\left( 0.381, \sqrt{0.381\times 0.619/@n[0]}\right) \)"
);
$q4mc -> extra(
"\(N\left( @m[0]/@n[0],  \sqrt{0.381\times 0.619/@n[0]}\right) \)", 
"\(N\left( @m[0]/@n[0],  \sqrt{ @m[0]/@n[0] \times (1-@m[0]/@n[0]) /@n[0]}\right)\)",
"\(N\left( 0.381, \sqrt{0.381\times 0.619/@m[0]}\right) \)",
"\(N\left( 0.381,  \sqrt{ @m[0]/@n[0] \times (1-@m[0]/@n[0]) /@n[0]}\right)\)"
);

#######Q5
@s5= rserve_eval('
tem <- (phat - 0.381) / sqrt(0.381*0.619/n)
round(tem, 3)
');

########Q6
@s6= rserve_eval('
2* round(pnorm(phat, mean=0.381, sd=sqrt(0.381*0.619/n), lower.tail = FALSE),4)
');

######Q7
$q7mc = new_multiple_choice();
$q7mc -> qa(
"What is an appropriate conclusion for the hypothesis test at the 5%
significance level?",
"There is no evidence to reject the hypothesis that the text in
question was in English."
);
$q7mc -> extra(
"There is evidence to reject the hypothesis that the text in question
was in English.",
"We can be sure that the text in question was in English.",
"We can be sure that the text in question was not in English."
);




#########################################################
## Main Text: where all text goes (Required)
Context()->texStrings;
BEGIN_TEXT
 It is known that the proportion of vowel letters in the English
language is 0.381. Suppose that you take a random sample of text containing 
@n[0] letters and find that the text contains @m[0] vowels. You
wonder whether you can make a guess about whether the text is written in
English or not based on this proportion.
$BR
$BR
(a)  \{ $q1mc -> print_q() \}
$BR
\{ $q1mc -> print_a() \}
$BR
$BR 

(b) \{ $q2mc -> print_q() \}
$BR
\{ $q2mc -> print_a() \}
$BR
$BR


(c) \{ $q3mc -> print_q() \}
$BR
\{ $q3mc -> print_a() \}
$BR
$BR

(d) \{ $q4mc -> print_q() \}
$BR
\{ $q4mc -> print_a() \}
$BR
$BR

(e) Find the z-score for the sample proportion assuming the null
hypothesis is true. Give your answer to four decimal places. \{ ans_rule(6) \}
$BR
$BR

(f) Use software to compute the P-value for this test. Your answer must be
rounded to four decimal places. \{ ans_rule(6) \} 
$BR
$BR

(g) \{ $q7mc -> print_q() \}
$BR
\{ $q7mc -> print_a() \}
$BR
$BR


END_TEXT
#########################################################
## Answers evaluation (Required)

ANS( radio_cmp( $q1mc -> correct_ans() ) );
ANS( radio_cmp( $q2mc -> correct_ans() ) );
ANS( radio_cmp( $q3mc -> correct_ans() ) );
ANS( radio_cmp( $q4mc -> correct_ans() ) );
ANS( num_cmp(@s5[0], tol=> 0.011) );
ANS( num_cmp(@s6[0], tol=> 0.011) );
ANS( radio_cmp( $q7mc -> correct_ans() ) );


#########################################################
## Solution (Optional but recommended)
Context()->texStrings;
BEGIN_SOLUTION
(a) The proportion of vowel letters in the language in
which the text is written is the parameter of interest. Note that here we
have in effect a two--stage sampling scheme, with a sample of text taken
from a larger text, which is itself a sample from the unknown language. 
$BR
$BR

(b) The null hypothesis is that this text is in English, i.e., that
the true proportion of vowels \(\pi \) for the language of the text is
0.381.
$BR
$BR

(c) The alternative hypothesis is that the text is not English, and
thus that the true proportion for language of the text is something other
than 0.381. Since we do not know whether the true proportion in other
languages would be higher or lower, we do not specify a direction. 
$BR
$BR

(d) Under the hypothesis the population proportion \(\pi \) is 0.381,
the sample proportion will be approximately Normal with mean 0.381 and
standard deviation
\[
\sqrt{\pi \left( 1-\pi \right) /@n[0]}=\sqrt{0.381\times 0.619/@n[0]}.
\]
$BR
$BR

(e) The z-score here is the standardised value of the sample
proportion, this being
\[
\frac{@phat[0]-0.381}{\sqrt{0.381\times 0.619/@n[0]}}=@s5[0].
\]
$BR
$BR

(f) This is a two--sided test, with alternative hypothesis that \(\pi
\neq 0.381.\) Hence both high and low values of the sample proportion
lead to the rejection of the null hypothesis. Since \(@phat[0] > 0.381\) and so lies in the upper tail, the P-value is found by finding the probability to the right of @phat[0] via the model in (d) and doubling. By software or tables, this is @s6[0]. 
$BR
$BR

(g) If the P-value from (f) is greater than 0.05, we can conclude
there is no evidence to reject the hypothesis that the text in question was
in English. Alternatively, if the P-value is less than 0.05, there is
evidence to reject the hypothesis that the text in question was in English.
$BR
$BR
To understand the P-value, for samples of the same size from English
we would expect to see a proportion of vowel letters at least this far from
0.381 about 100 \(\times\) @s6[0] of the time just by chance. It is up to us to
decide whether that is unlikely enough for us to reject the notion the text
is in English, or likely enough to think that it is. Another way to think
about this is if we were to draw 100 random samples of English text of size 
@n[0], you would expect about 100 \(\times\) @s6[0] of them to have
either at least this proportion of vowels, i.e., @phat[0] \(\times\) 100, or
less than its lower--tail equivalent, (2 \(\times\) 0.381-@phat[0]) \(\times\) 100, of
vowels. There is no firm rule that can tell us how likely is
 "likely enough", though the cut-off of
5% is suggested here and commonly used (i.e., if a sample statistic is in
the least likely 5% of values given the null hypothesis, we reject the null
hypothesis). But there is nothing inherently special about that 5% number.
$BR
$BR
As an example, the proportion of vowels in Czech is known to be 42.2%
(http://en.algoritmy.net/article/40382/Letter-frequency-Czech),
which indicates that if observing a proportion of vowel letters in our text
of \(212/500\) then if we decide to reject the null hypothesis we might have
been right, although the P-value is slightly more the 0.05. Note that if we
had thought ahead of time that the new text might have been in Czech, we may
have had a one-sided alternative hypothesis, i.e., \(H_{A}: \pi >0.381\). In which case, we would have found that the probability of getting the
sample proportion of \(212/500\), 1.95 standard deviations above the mean, was
about \(0.05/2=0.025\), i.e., would happen around 2.5% of the time
just by chance. That might have made us likely to reject the null
hypothesis, but it is dependent on having a reason to think that the true
proportion of vowels in the language of the text was higher than the true
proportion for English. You could also consider the null hypothesis that the
new text is in fact Czech, i.e., that it comes from a language having a
vowel proportion is 0.422. In that case, the sampling distribution of the
sample proportion would be \(N(0.422,0.022)\), and the normalized value
of the sample proportion would be \(z=0.09\). Using software
(such as pnorm() in R), we see that the probability of getting a
value at least 0.09 standard deviations in either direction from the true
proportion just by chance is 0.93, i.e., 93%. Thus, we would not reject the
null hypothesis that the new text is Czech based on this sample.

END_SOLUTION
ENDDOCUMENT();